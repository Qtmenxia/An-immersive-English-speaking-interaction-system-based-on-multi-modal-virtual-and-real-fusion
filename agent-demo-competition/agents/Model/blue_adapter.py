# blue_adapter.py
# -*- coding: utf-8 -*-
"""
Bridge between OpenAI-style ChatCompletion and vivo BlueLM (vivogpt/completions).
Author: <you>
Date  : 2025-04-25
"""

import base64
import hashlib
import hmac
import time
import uuid
import json
import random
import string
import urllib.parse as urlparse
from typing import List, Dict, Any, Optional

import requests   # pip install requests

# ---------------------------------------------------------------------------
# ğŸ”‘ 1. ä½ çš„ BlueLM å‡­æ®ï¼ˆå¯æ”¾åˆ°ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶é‡Œï¼‰
# ---------------------------------------------------------------------------
BLUE_APP_ID   = "2025761464"
BLUE_APP_KEY  = "uTfCZSgrEjvqauix"
BLUE_API_MODEL = "vivo-BlueLM-TB-Pro"          # ä½ åœ¨å¹³å°ä¸Šå¼€é€šçš„æ¨¡å‹ ID
BLUE_API_URL   = "https://api-ai.vivo.com.cn/vivogpt/completions"

# ---------------------------------------------------------------------------
# 2. BlueLM ç½‘å…³ç­¾åå·¥å…·
#    ç”Ÿæˆ X-AI-GATEWAY-* å¤´éƒ¨ï¼ˆå‚è€ƒå®˜æ–¹é‰´æƒè§„èŒƒï¼‰
# ---------------------------------------------------------------------------
def _gen_nonce(length: int = 12) -> str:
    return "".join(random.choices(string.ascii_lowercase + string.digits, k=length))

def _canonical_query(params: Dict[str, str]) -> str:
    """å°† query dict ç¼–ç å¹¶æŒ‰ key æ’åºåæ‹¼æ¥ï¼ˆRFC3986ï¼‰ã€‚"""
    if not params:
        return ""
    esc = urlparse.quote
    return "&".join(f"{esc(k)}={esc(str(v))}" for k, v in sorted(params.items()))

def _gen_signature(app_key: str, signing: str) -> str:
    digest = hmac.new(app_key.encode(), signing.encode(), hashlib.sha256).digest()
    return base64.b64encode(digest).decode()

def _sign_headers(
    app_id: str,
    app_key: str,
    method: str,
    uri: str,
    query: Dict[str, str]
) -> Dict[str, str]:
    """
    è¿”å› vivo ç½‘å…³æ‰€éœ€çš„ 5 ä¸ªç­¾åå¤´ï¼š
      X-AI-GATEWAY-APP-ID / -TIMESTAMP / -NONCE / -SIGNED-HEADERS / -SIGNATURE
    """
    timestamp = str(int(time.time()))
    nonce     = _gen_nonce()
    canonical_qs = _canonical_query(query)
    signed_headers_string = (
        f"x-ai-gateway-app-id:{app_id}\n"
        f"x-ai-gateway-timestamp:{timestamp}\n"
        f"x-ai-gateway-nonce:{nonce}"
    )

    signing_string = (
        f"{method.upper()}\n"           # â‘  HTTP Method
        f"{uri}\n"                      # â‘¡ HTTP URI
        f"{canonical_qs}\n"             # â‘¢ canonical_query_string
        f"{app_id}\n"                   # â‘£ app_id
        f"{timestamp}\n"                # â‘¤ timestamp
        f"{signed_headers_string}"      # â‘¥ signed_headers_string
    )

    sig = _gen_signature(app_key, signing_string)
    return {
        "X-AI-GATEWAY-APP-ID": app_id,
        "X-AI-GATEWAY-TIMESTAMP": timestamp,
        "X-AI-GATEWAY-NONCE": nonce,
        "X-AI-GATEWAY-SIGNED-HEADERS":
            "x-ai-gateway-app-id;x-ai-gateway-timestamp;x-ai-gateway-nonce",
        "X-AI-GATEWAY-SIGNATURE": sig,
    }

# ---------------------------------------------------------------------------
# 3. æ¶ˆæ¯è½¬æ¢ï¼šOpenAI messages  â†’  BlueLM prompt
#    è¿™é‡Œç»™å‡ºä¸€ç§é€šç”¨æ‹¼æ¥æ–¹å¼ï¼Œä½ å¯æŒ‰ä¸šåŠ¡è‡ªå®šä¹‰ã€‚
# ---------------------------------------------------------------------------
def _messages_to_prompt(messages: List[Dict[str, str]]) -> str:
    """æŠŠ OpenAI messages åˆ—è¡¨æ‹¼æˆå•å›åˆ promptï¼ˆç¤ºä¾‹æ¨¡æ¿ï¼‰ã€‚"""
    parts = []
    for m in messages:
        role = m["role"]
        if role == "system":
            parts.append(f"[SYSTEM] {m['content']}")
        elif role == "user":
            parts.append(f"[USER] {m['content']}")
        elif role == "assistant":
            parts.append(f"[ASSISTANT] {m['content']}")
        else:                       # tool / function / ...
            parts.append(f"[{role.upper()}] {m['content']}")
    # Blue æ¥å£åªæ”¶å•å­—ç¬¦ä¸² promptï¼Œæ‰€ä»¥ç”¨æ¢è¡Œåˆ†éš”
    return "\n".join(parts) + "\n[ASSISTANT] "

# ---------------------------------------------------------------------------
# 4. ä¸»é€‚é…ç±»ï¼šæ¨¡ä»¿ openai.ChatCompletion
# ---------------------------------------------------------------------------
class BlueChatCompletion:
    """
    ç”¨æ³•ï¼š
        from blue_adapter import BlueChatCompletion as ChatCompletion

        resp = ChatCompletion.create(
            model="gpt-3.5-turbo",           # ä»»æ„å ä½ç¬¦ï¼Œå†…éƒ¨ä¼šè¢«æ›¿æ¢
            messages=[{"role":"user","content":"ä»Šå¤©å¤©æ°”ï¼Ÿ"}],
            temperature=0.7,
        )
        print(resp["choices"][0]["message"]["content"])
    """

    @staticmethod
    def create(
        model: str,
        messages: List[Dict[str, str]],
        temperature: float = 0.9,
        top_p: float = 1.0,
        stream: bool = False,
        **kwargs: Any,
    ) -> Dict[str, Any]:
        """
        æ¥å£å®Œå…¨å…¼å®¹ openai.ChatCompletion.create çš„å¸¸ç”¨å‚æ•°ã€‚
        åªå®ç°æœ€å¸¸ç”¨å­—æ®µï¼Œæ›´å¤šå­—æ®µè¯·æŒ‰éœ€æ˜ å°„åˆ° Blue `extra`ã€‚
        """
        # ---------- a) ç»„è£… Blue è¯·æ±‚ ----------
        request_id = str(uuid.uuid4())
        query_params = {"requestId": request_id}

        body = {
            "prompt": _messages_to_prompt(messages),
            "model": BLUE_API_MODEL,
            "sessionId": kwargs.get("session_id", str(uuid.uuid4())),
            "extra": {
                "temperature": temperature,
                "top_p": top_p,
                # ä½ å¯ä»¥åœ¨è¿™é‡Œå¢åŠ  Blue æ”¯æŒçš„æ›´å¤šé‡‡æ · / æˆªæ­¢å‚æ•°
            },
        }

        headers = {
            "Content-Type": "application/json",
            **_sign_headers(
                BLUE_APP_ID,
                BLUE_APP_KEY,
                "POST",
                "/vivogpt/completions",
                query_params,
            ),
        }

        # ---------- b) å‘é€ ----------
        resp = requests.post(
            BLUE_API_URL,
            params=query_params,
            json=body,
            headers=headers,
            stream=stream,
            timeout=kwargs.get("timeout", 100),
        )
        resp.raise_for_status()
        payload = resp.json()

        if payload.get("code") != 0:
            raise RuntimeError(f"BlueLM error: {payload}")

        data = payload["data"]
        content = data.get("content", "")

        # ---------- c) è½¬å› OpenAI ChatCompletion ç»“æ„ ----------
        created = int(time.time())
        choice = {
            "index": 0,
            "finish_reason": (data.get("finishReason") or "STOP").lower(),
            "message": {
                "role": "assistant",
                "content": content,
            },
        }

        usage_raw = data.get("usage") or {}
        usage = {
            "prompt_tokens": usage_raw.get("promptTokens"),
            "completion_tokens": usage_raw.get("completionTokens"),
            "total_tokens": usage_raw.get("totalTokens"),
            # Blue ç›®å‰è¿˜æä¾› durationï¼Œå¯æŒ‰éœ€æ·»åŠ 
        }

        return {
            "id": data.get("requestId", request_id),
            "object": "chat.completion",
            "created": created,
            "model": model,
            "choices": [choice],
            "usage": usage,
        }


# ---------------------------------------------------------------------------
# 5. ç»™æ—§é¡¹ç›®åšâ€œé›¶æ”¹åŠ¨â€æ›¿æ¢çš„ä¸¤ç§æ€è·¯
# ---------------------------------------------------------------------------
#
# â‘  ç›´æ¥ import é‡å‘½å
# --------------------------------------------------
#   from blue_adapter import BlueChatCompletion as ChatCompletion
#
#   ChatCompletion.create( ... )  # è¯­ä¹‰ä¸ openai.ChatCompletion.create ç›¸åŒ
#
# â‘¡ monkey-patch openai
# --------------------------------------------------
#   import openai
#   from blue_adapter import BlueChatCompletion
#   openai.ChatCompletion = BlueChatCompletion
#
#   # ä¹‹åæ•´ç«™ä»»æ„æ—§ä»£ç çš„ `openai.ChatCompletion.create(...)`
#   # éƒ½ä¼šç»ç”± BlueChatCompletion è·¯ç”±åˆ° vivo BlueLMã€‚
#
# æ³¨æ„ï¼šå¦‚éœ€æµå¼(stream=True)è¿”å›ï¼Œå¯åœ¨ create() é‡Œ yield å­—ç¬¦ä¸²è¡Œï¼Œ
#       å†æŒ‰ OpenAI SSE åè®®æ‹¼æ¥ï¼›Blue æ¥å£é»˜è®¤æä¾› chunk-ed JSONï¼Œ
#       å…·ä½“å®ç°å¯å‚è€ƒå®˜æ–¹ç¤ºä¾‹æˆ–è‡ªè¡Œæ‰©å±•ã€‚
